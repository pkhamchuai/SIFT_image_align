{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc755df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import random\n",
    "import math\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm  # Using notebook version of tqdm\n",
    "from skimage.metrics import structural_similarity as ssim_fc\n",
    "\n",
    "# Suppress Qt warnings in some environments\n",
    "os.environ[\"QT_QPA_PLATFORM\"] = \"offscreen\"\n",
    "\n",
    "image_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02873d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 1. Image Loading & Preprocessing\n",
    "# ==========================================================\n",
    "def load_and_preprocess(img_path, image_size=256):\n",
    "    if not os.path.exists(img_path):\n",
    "        raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "    \n",
    "    img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Cannot read image or file is corrupted: {img_path}\")\n",
    "        \n",
    "    img = cv2.resize(img, (image_size, image_size))\n",
    "    \n",
    "    if len(img.shape) == 2:\n",
    "        gray = img\n",
    "        rgb_uint8 = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n",
    "    elif len(img.shape) == 3 and img.shape[2] == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        rgb_uint8 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    elif len(img.shape) == 3 and img.shape[2] == 4:\n",
    "        bgr = img[:, :, :3]\n",
    "        gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "        rgb_uint8 = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported image shape: {img.shape}\")\n",
    "    \n",
    "    gray_float = (gray / 255.0).astype(np.float32)\n",
    "    return gray_float, rgb_uint8\n",
    "\n",
    "def check_transform_validity(image, affine_matrix, black_thresh=0.05, rot_thresh_deg=45):\n",
    "    if image is None: return True, \"Image None\"\n",
    "    mean_val = np.mean(image)\n",
    "    if mean_val < black_thresh:\n",
    "        return True, f\"Too Dark (Mean={mean_val:.3f})\"\n",
    "    if affine_matrix is None: return True, \"Matrix None\"\n",
    "    angle_rad = np.arctan2(affine_matrix[1, 0], affine_matrix[0, 0])\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "    if abs(angle_deg) > rot_thresh_deg:\n",
    "        return True, f\"Excessive Rotation ({angle_deg:.1f} deg)\"\n",
    "    return False, \"OK\"\n",
    "\n",
    "# ==========================================================\n",
    "# 2. Metrics & Math Helpers (PURE NUMPY)\n",
    "# ==========================================================\n",
    "def mse(image1, image2):\n",
    "    return np.mean(np.square(image1 - image2))\n",
    "\n",
    "def tre(points1, points2):\n",
    "    return np.mean(np.sqrt(np.sum((points1 - points2)**2, axis=0)))\n",
    "\n",
    "def ssim_color_aware(image1, image2):\n",
    "    kwargs = {'data_range': image2.max() - image2.min()}\n",
    "    if image1.ndim == 3:\n",
    "        kwargs['channel_axis'] = -1\n",
    "    try:\n",
    "        output = ssim_fc(image1, image2, **kwargs)\n",
    "    except ValueError:\n",
    "        output = 0.0\n",
    "    return -output\n",
    "\n",
    "def affine_to_DVF_numpy(affine_matrix, H, W):\n",
    "    if affine_matrix is None:\n",
    "        return np.zeros((1, 2, H, W))\n",
    "    \n",
    "    x = np.arange(W)\n",
    "    y = np.arange(H)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    \n",
    "    ones = np.ones_like(xx)\n",
    "    coords = np.vstack([xx.ravel(), yy.ravel(), ones.ravel()])\n",
    "    \n",
    "    new_coords = affine_matrix @ coords\n",
    "    \n",
    "    disp_x = new_coords[0, :] - xx.ravel()\n",
    "    disp_y = new_coords[1, :] - yy.ravel()\n",
    "    \n",
    "    disp = np.stack([disp_x.reshape(H, W), disp_y.reshape(H, W)], axis=0)\n",
    "    return disp[np.newaxis, ...] \n",
    "\n",
    "# ==========================================================\n",
    "# 3. Visualization Helpers\n",
    "# ==========================================================\n",
    "def overlay_points_color(image, points, color=(0, 255, 0), radius=5):\n",
    "    if len(image.shape) == 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    if image.max() <= 2.0:\n",
    "        image = ((image - image.min()) / (image.max() - image.min()) * 255).astype(np.uint8)\n",
    "    else:\n",
    "        image = image.astype(np.uint8).copy()\n",
    "    if points is not None and len(points) > 0:\n",
    "        try:\n",
    "            for point in points.T:\n",
    "                x, y = int(point[0]), int(point[1])\n",
    "                cv2.circle(image, (x, y), radius, color, -1)\n",
    "        except Exception: pass\n",
    "    return image\n",
    "\n",
    "def draw_lines_one_image_color(image, points1, points2, line_thickness=1, opacity=0.5, line_color=None):\n",
    "    if len(image.shape) == 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    if image.max() <= 2.0:\n",
    "        image = ((image - image.min()) / (image.max() - image.min()) * 255).astype(np.uint8)\n",
    "    else:\n",
    "        image = image.astype(np.uint8).copy()\n",
    "\n",
    "    bright_colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (0, 255, 255), (255, 0, 255), (255, 128, 0)]\n",
    "    if points1 is not None and points2 is not None and len(points1) > 0 and len(points2) > 0:\n",
    "        for pt1, pt2 in zip(points1.T, points2.T):\n",
    "            x1, y1 = int(pt1[0]), int(pt1[1])\n",
    "            x2, y2 = int(pt2[0]), int(pt2[1])\n",
    "            color_to_use = line_color if line_color is not None else random.choice(bright_colors)\n",
    "            cv2.line(image, (x1, y1), (x2, y2), color_to_use, line_thickness)\n",
    "            overlay = image.copy()\n",
    "            cv2.line(overlay, (x1, y1), (x2, y2), color_to_use, line_thickness)\n",
    "            cv2.addWeighted(overlay, opacity, image, 1 - opacity, 0, image)\n",
    "    return image\n",
    "\n",
    "def create_checkerboard_color(image1, image2):\n",
    "    checkerboard = np.zeros_like(image1)\n",
    "    width = checkerboard.shape[1]\n",
    "    tile_size = width / 10\n",
    "    for i in range(checkerboard.shape[0]):\n",
    "        for j in range(checkerboard.shape[1]):\n",
    "            num = (math.floor(i / tile_size) + math.floor(j / tile_size)) % 2\n",
    "            if num == 0: checkerboard[i, j] = image1[i, j]\n",
    "            else: checkerboard[i, j] = image2[i, j]\n",
    "    return checkerboard\n",
    "\n",
    "def signaturebar_gray(fig, text, fontsize=10, pad=5, xpos=20, ypos=7.5, rect_kw={\"facecolor\": \"gray\", \"edgecolor\": None}, text_kw={\"color\": \"w\"}):\n",
    "    w, h = fig.get_size_inches()\n",
    "    height = ((fontsize + 2 * pad) / 72.) / h\n",
    "    rect_inner = plt.Rectangle((0, 0), 1, height, transform=fig.transFigure, clip_on=False, **rect_kw)\n",
    "    fig.axes[0].add_patch(rect_inner)\n",
    "    fig.text(xpos / 72. / h, ypos / 72. / h, text, fontsize=fontsize, **text_kw)\n",
    "    fig.subplots_adjust(bottom=fig.subplotpars.bottom + height)\n",
    "    return fig\n",
    "\n",
    "def DL_affine_plot_color(name, dir_name, image1_name, image2_name, image1, image2, image3,\n",
    "                       matches1, matches2, matches3, desc1, desc2, affine_params_true=None, \n",
    "                       affine_params_predict=None, heatmap1=None, heatmap2=None, plot=0, alpha=0.3):\n",
    "    try:\n",
    "        mse_before = mse(matches1, matches2)\n",
    "        tre_before = tre(matches1, matches2)\n",
    "        mse12 = mse(matches3, matches2)\n",
    "        tre12 = tre(matches3, matches2)\n",
    "    except:\n",
    "        mse_before, tre_before, mse12, tre12 = np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "    mse12_image_before = mse(image1, image2)\n",
    "    mse12_image = mse(image3, image2)\n",
    "    ssim12_image_before = ssim_color_aware(image1, image2)\n",
    "    ssim12_image = ssim_color_aware(image3, image2)\n",
    "\n",
    "    if plot == 1:\n",
    "        fig, axes = plt.subplots(subplot_kw={'projection': None}, num=None, figsize=(20, 10))\n",
    "        fig, axes = plt.subplot_mosaic(\"BCFD;AGHE\", figsize=(20, 10))\n",
    "\n",
    "        red = (255, 0, 0); green = (0, 255, 0); orange = (255, 165, 0); blue = (0, 0, 155)\n",
    "        \n",
    "        overlaid1 = overlay_points_color(image1.copy(), matches1, color=red, radius=1)\n",
    "        overlaid2 = overlay_points_color(image2.copy(), matches2, color=green, radius=1)\n",
    "        overlaid3 = overlay_points_color(image3.copy(), matches3, color=orange, radius=1)\n",
    "        overlaidD = overlay_points_color(overlaid2.copy(), matches3, color=orange, radius=1)\n",
    "        overlaidD = overlay_points_color(overlaidD.copy(), matches1, color=red, radius=1)\n",
    "        overlaidE = overlay_points_color(overlaid2.copy(), matches3, color=orange, radius=1)\n",
    "        overlaidH = overlay_points_color(overlaid2.copy(), matches1, color=red, radius=1)\n",
    "\n",
    "        axes[\"F\"].imshow(overlaid3)\n",
    "        axes[\"F\"].set_title(f\"Warped\")\n",
    "        axes[\"F\"].axis('off'); axes['F'].grid(True)\n",
    "\n",
    "        axes[\"B\"].imshow(overlaid1)\n",
    "        try: axes[\"B\"].set_title(f\"Source,\\n{matches1.shape}, {matches2.shape}, {matches3.shape}\") \n",
    "        except: axes[\"B\"].set_title(f\"Source,\\nMSE: {mse12_image_before:.4f} SSIM: {ssim12_image_before:.4f}\")\n",
    "        axes[\"B\"].axis('off'); axes['B'].grid(True)\n",
    "\n",
    "        axes[\"C\"].imshow(overlaid2)\n",
    "        if affine_params_true is not None: axes[\"C\"].set_title(f\"Target, {affine_params_true}\")\n",
    "        else: axes[\"C\"].set_title(f\"Target (unsupervised)\")\n",
    "        axes[\"C\"].axis('off'); axes['C'].grid(True)\n",
    "        \n",
    "        try:\n",
    "            imgH = draw_lines_one_image_color(overlaidH, matches2, matches1, line_color=blue)\n",
    "            axes[\"H\"].imshow(imgH)\n",
    "        except: axes[\"H\"].imshow(overlaidH)\n",
    "        axes[\"H\"].set_title(f\"Before, Error lines. MSE: {mse_before:.4f}, TRE: {tre_before:.4f}\")\n",
    "        axes[\"H\"].axis('off')\n",
    "        \n",
    "        try:\n",
    "            imgD = draw_lines_one_image_color(overlaidD, matches3, matches1, line_color=blue)\n",
    "            axes[\"D\"].imshow(imgD)\n",
    "        except: axes[\"D\"].imshow(overlaidD)\n",
    "\n",
    "        skip = 8\n",
    "        X, Y = np.meshgrid(np.arange(0, 256), np.arange(0, 256))\n",
    "        \n",
    "        if affine_params_predict is not None:\n",
    "            try:\n",
    "                DVF = affine_to_DVF_numpy(affine_params_predict, 256, 256)[0]\n",
    "                U = -1 * DVF[0, :, :]\n",
    "                V = 1 * DVF[1, :, :]\n",
    "                axes[\"D\"].quiver(X[::skip, ::skip], Y[::skip, ::skip], U[::skip, ::skip], V[::skip, ::skip], \n",
    "                                 color='r', scale=1, scale_units='xy', alpha=alpha)\n",
    "            except Exception as e: pass\n",
    "\n",
    "        axes[\"D\"].set_xlim(0, 255); axes[\"D\"].set_ylim(255, 0)\n",
    "        try: axes[\"D\"].set_title(f\"Source -> Warped, Xformation.\\nMSE: {mse(matches1, matches3):.4f}, TRE: {tre(matches1, matches3):.4f}\")\n",
    "        except: axes[\"D\"].set_title(f\"Source -> Warped, Xformation.\")\n",
    "        axes[\"D\"].axis('off')\n",
    "\n",
    "        try:\n",
    "            imgE = draw_lines_one_image_color(overlaidE, matches2, matches3, line_color=blue)\n",
    "            axes[\"E\"].imshow(imgE)\n",
    "        except: axes[\"E\"].imshow(overlaidE)\n",
    "        axes[\"E\"].set_title(f\"After, Error lines. MSE: {mse12:.4f}, TRE: {tre12:.4f}\")\n",
    "        axes[\"E\"].axis('off')\n",
    "\n",
    "        checkerboard1 = create_checkerboard_color(image1, image2)\n",
    "        axes[\"A\"].imshow(checkerboard1)\n",
    "        axes[\"A\"].set_title(f\"Original - Target, MSE: {mse12_image_before:.4f}, SSIM: {ssim12_image_before:.4f}\")\n",
    "        axes[\"A\"].axis('off')\n",
    "\n",
    "        checkerboard2 = create_checkerboard_color(image3, image2)\n",
    "        axes[\"G\"].imshow(checkerboard2)\n",
    "        axes[\"G\"].set_title(f\"Warped - Target, MSE: {mse12_image:.4f}, SSIM: {ssim12_image:.4f}\")\n",
    "        axes[\"G\"].axis('off')\n",
    "        \n",
    "        plt.tight_layout()  \n",
    "        if not os.path.exists(dir_name): os.makedirs(dir_name) \n",
    "        save_file_name = os.path.join(dir_name, f\"{name}_{image1_name}.png\")\n",
    "\n",
    "        if os.path.exists(save_file_name):\n",
    "            suffix = 1\n",
    "            while True:\n",
    "                new_file_name = os.path.join(dir_name, f\"{name}_{image1_name}_{suffix}.png\")\n",
    "                if not os.path.exists(new_file_name):\n",
    "                    save_file_name = new_file_name\n",
    "                    break\n",
    "                suffix += 1\n",
    "\n",
    "        signaturebar_gray(fig, f\"{name}: {image2_name}\", fontsize=20, pad=5, xpos=20, ypos=7.5,\n",
    "                rect_kw={\"facecolor\": \"gray\", \"edgecolor\": None}, text_kw={\"color\": \"w\"})\n",
    "        fig.savefig(save_file_name)\n",
    "        plt.close(fig) # Prevent Jupyter from displaying 100 images inline automatically\n",
    "\n",
    "    return matches3, mse_before, mse12, tre_before, tre12, mse12_image_before, mse12_image, ssim12_image_before, ssim12_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "441c7667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sift_match(src_gray, tgt_gray, nn_thresh):\n",
    "    \"\"\"Extract and match keypoints using SIFT.\"\"\"\n",
    "    \n",
    "    src_uint8 = (src_gray * 255).astype(np.uint8)\n",
    "    tgt_uint8 = (tgt_gray * 255).astype(np.uint8)\n",
    "    \n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1_cv, desc1 = sift.detectAndCompute(src_uint8, None)\n",
    "    kp2_cv, desc2 = sift.detectAndCompute(tgt_uint8, None)\n",
    "    \n",
    "    heatmap1, heatmap2 = None, None \n",
    "    \n",
    "    if desc1 is None or desc2 is None or len(kp1_cv) < 3 or len(kp2_cv) < 3:\n",
    "        return np.array([]), np.array([]), heatmap1, heatmap2\n",
    "        \n",
    "    bf = cv2.BFMatcher()\n",
    "    \n",
    "    def match_sift_ratio(d1, d2, ratio):\n",
    "        matches_knn = bf.knnMatch(d1, d2, k=2)\n",
    "        good = []\n",
    "        for m_n in matches_knn:\n",
    "            if len(m_n) == 2:\n",
    "                m, n = m_n\n",
    "                if m.distance < ratio * n.distance:\n",
    "                    good.append(m)\n",
    "        return good\n",
    "        \n",
    "    threshold = nn_thresh\n",
    "    good_matches = match_sift_ratio(desc1, desc2, threshold)\n",
    "    \n",
    "    while len(good_matches) < 4 and threshold < 0.95:\n",
    "        threshold += 0.1\n",
    "        good_matches = match_sift_ratio(desc1, desc2, threshold)\n",
    "        \n",
    "    if len(good_matches) < 3:\n",
    "        return np.array([]), np.array([]), heatmap1, heatmap2\n",
    "        \n",
    "    m1 = np.float32([kp1_cv[m.queryIdx].pt for m in good_matches])\n",
    "    m2 = np.float32([kp2_cv[m.trainIdx].pt for m in good_matches])\n",
    "    \n",
    "    return m1, m2, heatmap1, heatmap2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc67d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# ⚙️ CONFIGURATION \n",
    "# =================================================================\n",
    "\n",
    "# Option 1: Provide a direct list of image paths [source1, target1, source2, target2, ...]\n",
    "# Leave empty [] if you want to use the CSV file instead.\n",
    "img_list = ['test_images/NIR_M121HW_0.jpg', 'test_images/RGB_M121LW_0.jpg'] \n",
    "\n",
    "# Option 2: Provide a path to a CSV or TXT file (src, tgt per line)\n",
    "img_file = \"my_pairs.csv\" \n",
    "\n",
    "# Thresholds and Methods\n",
    "nn_threshold = 0.7\n",
    "method = 'RANSAC' # Choose between 'RANSAC' or 'LMEDS'\n",
    "\n",
    "# Saving Options\n",
    "save_images = 1   # 0: Save only plot | 1: Save plot AND original color images\n",
    "\n",
    "# ================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d95f7aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 pairs to process.\n",
      "Using Pure OpenCV/NumPy SIFT Pipeline...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m csv_rows = []\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# --- 2. Run Inference Loop ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (src_path, tgt_path) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_pairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mProcessing Pairs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     32\u001b[39m         src_gray, src_rgb = load_and_preprocess(src_path, image_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/pkhamchuai/codes/SIFT_image_align/.venv/lib/python3.12/site-packages/tqdm/notebook.py:234\u001b[39m, in \u001b[36mtqdm_notebook.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    232\u001b[39m unit_scale = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.unit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m    233\u001b[39m total = \u001b[38;5;28mself\u001b[39m.total * unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.total\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m \u001b[38;5;28mself\u001b[39m.container = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28mself\u001b[39m.container.pbar = proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.displayed = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/pkhamchuai/codes/SIFT_image_align/.venv/lib/python3.12/site-packages/tqdm/notebook.py:108\u001b[39m, in \u001b[36mtqdm_notebook.status_printer\u001b[39m\u001b[34m(_, total, desc, ncols)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[32m    110\u001b[39m     pbar = IProgress(\u001b[38;5;28mmin\u001b[39m=\u001b[32m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m=total)\n",
      "\u001b[31mImportError\u001b[39m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "# --- 1. Prepare Image List ---\n",
    "image_pairs = []\n",
    "if img_list and len(img_list) > 0:\n",
    "    if len(img_list) % 2 != 0:\n",
    "        raise ValueError(\"Error: img_list must have an even number of arguments.\")\n",
    "    for i in range(0, len(img_list), 2):\n",
    "        image_pairs.append((img_list[i], img_list[i+1]))\n",
    "elif img_file and os.path.exists(img_file):\n",
    "    with open(img_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(',')\n",
    "            if len(parts) >= 2:\n",
    "                image_pairs.append((parts[0].strip(), parts[1].strip()))\n",
    "else:\n",
    "    raise ValueError(\"Error: Must provide valid img_list or img_file path.\")\n",
    "\n",
    "print(f\"Found {len(image_pairs)} pairs to process.\")\n",
    "print(\"Using Pure OpenCV/NumPy SIFT Pipeline...\")\n",
    "\n",
    "est_method_flag = cv2.LMEDS if method == 'LMEDS' else cv2.RANSAC\n",
    "\n",
    "# Prepare output directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "output_dir = f\"output/SIFT_Standalone_Jupyter_{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "csv_rows = []\n",
    "\n",
    "# --- 2. Run Inference Loop ---\n",
    "for i, (src_path, tgt_path) in enumerate(tqdm(image_pairs, desc=\"Processing Pairs\")):\n",
    "    try:\n",
    "        src_gray, src_rgb = load_and_preprocess(src_path, image_size)\n",
    "        tgt_gray, tgt_rgb = load_and_preprocess(tgt_path, image_size)\n",
    "    except Exception as e:\n",
    "        print(f\"Skip pair {i} due to error: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Extract and match points using SIFT\n",
    "    m1, m2, heatmap1, heatmap2 = run_sift_match(src_gray, tgt_gray, nn_threshold)\n",
    "\n",
    "    prefix = f\"pair_{i:03d}_{os.path.basename(src_path).split('.')[0]}\"\n",
    "    text_log = \"SIFT Failed\"\n",
    "    \n",
    "    M_est = None\n",
    "    warped_src_rgb = None\n",
    "    m1_trans_plot = None\n",
    "\n",
    "    # Estimate affine transformation matrix\n",
    "    if len(m1) >= 3:\n",
    "        M_est, inliers = cv2.estimateAffinePartial2D(m1, m2, method=est_method_flag)\n",
    "\n",
    "    if M_est is not None:\n",
    "        warped_src_rgb = cv2.warpAffine(src_rgb, M_est, (image_size, image_size))\n",
    "        \n",
    "        is_bad, reason = check_transform_validity(warped_src_rgb, M_est)\n",
    "        if not is_bad:\n",
    "            inl_cnt = int(np.sum(inliers))\n",
    "            text_log = f\"SIFT Win (Inliers:{inl_cnt}/{len(m1)})\"\n",
    "            m1_trans_plot = cv2.transform(m1.reshape(-1, 1, 2), M_est).reshape(-1, 2).T\n",
    "        else:\n",
    "            text_log = f\"Bad Transform: {reason}\"\n",
    "\n",
    "    # Prepare plot points\n",
    "    m1_plot = m1.T if len(m1) > 0 else None\n",
    "    m2_plot = m2.T if len(m2) > 0 else None\n",
    "\n",
    "    # --- 3. Plot color results using DL_affine_plot_color ---\n",
    "    # The function saves the image automatically to the output_dir\n",
    "    DL_affine_plot_color(prefix, output_dir,\n",
    "                   \"Result\", text_log, src_rgb, tgt_rgb,\n",
    "                   warped_src_rgb if warped_src_rgb is not None else src_rgb,\n",
    "                   m1_plot, m2_plot, m1_trans_plot,\n",
    "                   None, None,\n",
    "                   affine_params_true=None,\n",
    "                   affine_params_predict=M_est, \n",
    "                   heatmap1=heatmap1, heatmap2=heatmap2, plot=1)\n",
    "\n",
    "    # --- 4. Save individual color images and prepare CSV data ---\n",
    "    csv_src_path = src_path\n",
    "    csv_tgt_path = tgt_path\n",
    "    csv_warp_path = \"\"\n",
    "\n",
    "    if save_images == 1:\n",
    "        save_src = os.path.join(output_dir, f\"{prefix}_src.png\")\n",
    "        save_tgt = os.path.join(output_dir, f\"{prefix}_tgt.png\")\n",
    "        \n",
    "        cv2.imwrite(save_src, cv2.cvtColor(src_rgb, cv2.COLOR_RGB2BGR))\n",
    "        cv2.imwrite(save_tgt, cv2.cvtColor(tgt_rgb, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        csv_src_path = save_src\n",
    "        csv_tgt_path = save_tgt\n",
    "\n",
    "        if warped_src_rgb is not None:\n",
    "            save_warp = os.path.join(output_dir, f\"{prefix}_warp.png\")\n",
    "            cv2.imwrite(save_warp, cv2.cvtColor(warped_src_rgb, cv2.COLOR_RGB2BGR))\n",
    "            csv_warp_path = save_warp\n",
    "\n",
    "    csv_rows.append([i, csv_src_path, csv_tgt_path, csv_warp_path, len(m1), text_log])\n",
    "\n",
    "# --- 5. Generate CSV file ---\n",
    "csv_file_path = os.path.join(output_dir, \"results_log.csv\")\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['index', 'source', 'target', 'warped', 'num_matches', 'status'])\n",
    "    writer.writerows(csv_rows)\n",
    "\n",
    "print(f\"\\nFinished processing. Results saved to {output_dir}\")\n",
    "print(f\"CSV Log generated at: {csv_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
